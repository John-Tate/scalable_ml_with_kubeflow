{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Serving Models with Seldon Core - Sklearn Server\n",
    "\n",
    "In this example, we'll use SeldonCore to easily deploy a pickled sklearn model as an endpoint with the ability to scale horizontally\n",
    "\n",
    "We'll start by building a simple logistic regression on the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = load_iris(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(multi_class='ovr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/john/anaconda3/envs/kubeflow/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='ovr', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New Data\n",
    "data = [[5,\n",
    "         3,\n",
    "         1.5,\n",
    "         0.2]]\n",
    "\n",
    "\n",
    "preds = lr.predict_proba(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions for new data\n",
    "for n in range(0,3):\n",
    "    print(f\"class{n}: \",\"{:.4%}\".format(preds[0][n]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We'll save our model locally where Minikube can mount it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a folder\n",
    "!mkdir -p pv_storage/_storage/sklearn_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pickled Joblib models *MUST* be named **model.joblib** for Seldon to pick them up correctly. \n",
    "\n",
    "If you would like to identify your models, you can do so by naming the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./seldon_models/sklearn_iris/model.joblib']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dump(lr,\"./pv_storage/sklearn_iris/model.joblib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we'll need to mount the pv_storage file to minikube.\n",
    "\n",
    "In a **new terminal session** make sure you're in the repository's root and run:\n",
    "\n",
    "```\n",
    "minikube mount $(pwd)/pv_storage/:/mkdata\n",
    "```\n",
    "\n",
    "This will allow minikube to access files in the pv_storage folder - MiniKube will see it as 'mkdata' \n",
    "\n",
    "This terminal session has to stay running as long as we're working with this model. A Persistent Volume + and Persistent Volume Claim would be a more long-term solution; or hosting the model in cloud storage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "apiVersion: machinelearning.seldon.io/v1alpha2\r\n",
      "kind: SeldonDeployment\r\n",
      "metadata:\r\n",
      "  name: sklearn\r\n",
      "spec:\r\n",
      "  name: iris\r\n",
      "  predictors:\r\n",
      "  - graph:\r\n",
      "      children: []\r\n",
      "      implementation: SKLEARN_SERVER\r\n",
      "      modelUri: <<FILL IN>>\r\n",
      "      name: classifier\r\n",
      "    name: default\r\n",
      "    replicas: 1\r\n",
      "  volumes:\r\n",
      "    name: host-mount\r\n",
      "    hostpath:\r\n",
      "      path: <<FILL IN>>"
     ]
    }
   ],
   "source": [
    "!cat sklearn_iris.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An simple yaml file that controls our model's deployment:\n",
    "\n",
    "* Seldon Deployment\n",
    "* Named sklearn\n",
    "* Model is named iris (goes into pod names, endpoint names, etc)\n",
    "* Its an sklearn model so we'll use an sklearn server (XGBoost and Tensorflow are also options)\n",
    "    * Other models can be served with Seldon, but they require packaging the model into a container instead of pulling from a URI\n",
    "* modelUri defines the path to the model.joblib file\n",
    "    * This can be hosted many places:\n",
    "        * A volume or PVC\n",
    "        * Google Cloud Storage\n",
    "        * AWS S3\n",
    "        * Azure Blob\n",
    "\n",
    "* Volumes tells k8s to make the volume we'll mount available to this pod\n",
    "\n",
    "\n",
    "Fill in the location of your model (or use the sklean_iris_example.yaml file which has been completed to match the above host-mount configuration)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can submit the process to our cluster using Kubectl:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl apply -f sklearn_iris_example.yaml"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:kubeflow]",
   "language": "python",
   "name": "conda-env-kubeflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
